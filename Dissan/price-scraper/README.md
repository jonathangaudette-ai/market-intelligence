# Dissan Price Scraper

Web scraper automatisÃ© pour l'analyse de prix compÃ©titeurs sur 13 sites canadiens.

## ğŸ“Š Vue d'Ensemble

**Objectif:** Extraire les prix de 576 produits commerciaux Dissan chez 13 compÃ©titeurs canadiens

**MÃ©thode:** Web scraping automatisÃ© avec Playwright + Matching intelligent (SKU + Nom)

**Output:** Fichier Excel consolidÃ© avec prix par compÃ©titeur + statistiques

## ğŸ—ï¸ Architecture

```
price-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                    # Point d'entrÃ©e principal
â”‚   â”œâ”€â”€ config.ts                  # Configuration globale
â”‚   â”œâ”€â”€ types.ts                   # Types TypeScript
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base-scraper.ts        # Classe de base abstraite
â”‚   â”‚   â”œâ”€â”€ swish-scraper.ts       # Scraper Swish
â”‚   â”‚   â”œâ”€â”€ grainger-scraper.ts    # Scraper Grainger
â”‚   â”‚   â””â”€â”€ ...                    # Autres scrapers
â”‚   â”œâ”€â”€ matchers/
â”‚   â”‚   â”œâ”€â”€ sku-matcher.ts         # Matching par SKU exact
â”‚   â”‚   â””â”€â”€ name-matcher.ts        # Matching par nom/marque
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ rate-limiter.ts        # Rate limiting
â”‚   â”‚   â”œâ”€â”€ checkpoint-manager.ts  # Gestion checkpoints
â”‚   â”‚   â””â”€â”€ logger.ts              # Logging
â”‚   â””â”€â”€ exporters/
â”‚       â””â”€â”€ excel-exporter.ts      # Export Excel
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ checkpoints/               # Sauvegardes progression
â”‚   â””â”€â”€ logs/                      # Fichiers de logs
â””â”€â”€ package.json
```

## ğŸ¯ CompÃ©titeurs (13 sites)

### PrioritÃ© 1 (5 sites nationaux)
1. **Swish Maintenance** (swish.ca) - Leader produits verts
2. **Grainger Canada** (grainger.ca) - 100,000+ produits MRO
3. **ULINE Canada** (uline.ca) - 43,000+ produits
4. **Bunzl Cleaning & Hygiene** (bunzlch.ca) - Plus grand distributeur
5. **Imperial Dade** (imperialdade.com) - 35 emplacements

### PrioritÃ© 2 (5 sites e-commerce)
6. **CleanItSupply** (cleanitsupply.ca) - Prix de gros
7. **United Canada** (unitedcanadainc.com) - Multi-secteurs
8. **NexDay Supply** (nexdaysupply.ca) - Livraison rapide
9. **Clean Spot** (cleanspot.ca) - Rabais grossistes
10. **Checkers Cleaning** (checkerscleaningsupply.com) - Depuis 1983

### PrioritÃ© 3 (3 sites QuÃ©bec)
11. **V-TO inc.** (vto.qc.ca) - Fabricant/distributeur QC
12. **Lalema Express** (lalemaexpress.com) - MontrÃ©al
13. **SaniDÃ©pÃ´t** (sani-depot.ca) - 90+ ans expÃ©rience

## ğŸš€ Installation

```bash
cd Dissan/price-scraper
npm install
npx playwright install
```

## ğŸ“ Commandes Disponibles

### DÃ©veloppement et Test
```bash
npm run dev              # Mode dÃ©veloppement
npm run scrape:test      # Test sur 50 produits Ã©chantillon
```

### Production
```bash
npm run scrape:all       # Scraping complet (13 sites Ã— 576 produits)
npm run scrape:priority1 # Sites prioritÃ© 1 uniquement
npm run scrape:priority2 # Sites prioritÃ© 2 uniquement
npm run scrape:priority3 # Sites prioritÃ© 3 uniquement
npm run scrape:site swish # Scraper un seul site
npm run scrape:update    # Mise Ã  jour incrÃ©mentale (re-scrape produits trouvÃ©s)
```

### Analyse
```bash
npm run analyze          # GÃ©nÃ©rer rapports Excel consolidÃ©s
npm run stats            # Afficher statistiques de progression
npm run validate         # Valider rÃ©sultats (cohÃ©rence prix, URLs)
```

## ğŸ”§ Configuration

### Fichiers de Config
- `../competitors-config.json` - Configuration des 13 sites (sÃ©lecteurs CSS, rate limiting)
- `src/config.ts` - ParamÃ¨tres globaux du scraper

### ParamÃ¨tres ClÃ©s
- **Rate Limiting:** 2-3 secondes entre requÃªtes
- **Timeout:** 30 secondes par requÃªte
- **Max Retries:** 3 tentatives
- **Checkpoint:** Sauvegarde tous les 50 produits
- **User-Agent:** Rotation de 5 user-agents

## ğŸ¯ StratÃ©gie de Matching

### Ã‰tape 1: Recherche par SKU exact (prioritÃ© haute)
1. Rechercher le SKU nettoyÃ© dans la barre de recherche
2. VÃ©rifier si rÃ©sultat exact (SKU identique)
3. Si match â†’ extraire prix et dÃ©tails
4. Si pas de match â†’ passer Ã  l'Ã©tape 2

### Ã‰tape 2: Recherche par Nom + Marque (fallback)
1. Construire requÃªte: `"[MARQUE] [NOM_PRODUIT]"`
2. Exemple: `"Rubbermaid WAVEBRAKE Bucket"`
3. Filtrer rÃ©sultats par similaritÃ© de nom (>80% Levenshtein)
4. VÃ©rifier correspondance marque
5. Si match confiant â†’ extraire prix
6. Sinon â†’ marquer "non trouvÃ©"

## ğŸ“‚ Fichiers GÃ©nÃ©rÃ©s

### RÃ©sultats par Site
```
../results/prix-par-site/
â”œâ”€â”€ swish-results.json         # 576 produits Swish
â”œâ”€â”€ grainger-results.json      # 576 produits Grainger
â”œâ”€â”€ ...
â””â”€â”€ sanidepot-qc-results.json  # 576 produits SaniDÃ©pÃ´t
```

### Rapports ConsolidÃ©s
```
../prix-competiteurs-final.xlsx      # Base de donnÃ©es complÃ¨te (576 lignes Ã— 40+ colonnes)
../rapport-prix-competiteurs.xlsx    # Analyses, graphiques, recommandations
```

### Logs
```
data/logs/
â”œâ”€â”€ scraping-2024-11-18.log    # Log complet
â”œâ”€â”€ errors-2024-11-18.log      # Erreurs uniquement
â””â”€â”€ stats-2024-11-18.json      # Statistiques JSON
```

## ğŸ“Š MÃ©triques de SuccÃ¨s

| MÃ©trique | Objectif |
|----------|----------|
| Taux de match SKU | >60% |
| Taux de match Nom | >25% |
| Taux total trouvÃ© | >80% |
| PrÃ©cision prix | >95% |
| Temps moyen/produit | <10s |
| Taux d'erreur | <5% |

## ğŸ›¡ï¸ Gestion des Erreurs

### Types d'Erreurs
- **Timeout** (30s) â†’ Retry 3x avec dÃ©lai exponentiel
- **403 Forbidden** â†’ Rate limiting dÃ©tectÃ©, augmenter dÃ©lais
- **404 Not Found** â†’ Page n'existe pas, marquer comme "non trouvÃ©"
- **SÃ©lecteur introuvable** â†’ Structure HTML changÃ©e, vÃ©rifier sÃ©lecteurs
- **Connexion perdue** â†’ Retry avec backoff exponentiel

### StratÃ©gie de Recovery
1. Retry automatique (max 3 tentatives)
2. Sauvegarde checkpoint tous les 50 produits
3. Logs dÃ©taillÃ©s pour debugging
4. Continuer avec produit suivant en cas d'Ã©chec

## ğŸ”„ Mise Ã  Jour des Prix

**FrÃ©quence recommandÃ©e:** Mensuelle ou trimestrielle

```bash
npm run scrape:update
```

**Fonctionnement:**
1. Charge rÃ©sultats prÃ©cÃ©dents
2. Re-scrape uniquement produits trouvÃ©s la derniÃ¨re fois
3. Met Ã  jour fichier Excel
4. Compare avec prix prÃ©cÃ©dents (delta %)

## ğŸ“ˆ Monitoring

### Logs Ã  Surveiller
- Taux d'erreur par site
- Temps d'exÃ©cution
- Nombre de produits trouvÃ©s (variations)

### Alertes
- Si taux d'erreur >20% sur un site â†’ vÃ©rifier structure HTML
- Si temps d'exÃ©cution double â†’ optimiser ou vÃ©rifier connexion
- Si produits trouvÃ©s chute >30% â†’ vÃ©rifier sÃ©lecteurs

## ğŸš¨ Troubleshooting

### ProblÃ¨me: Bannissement IP (403)
**Solution:** Augmenter rate limiting (3-4s), utiliser proxies

### ProblÃ¨me: Produits non trouvÃ©s (>30%)
**Solution:** VÃ©rifier sÃ©lecteurs CSS, ajuster stratÃ©gie de matching

### ProblÃ¨me: Prix mal extraits
**Solution:** VÃ©rifier format prix (regex), valider sÃ©lecteur `.product-price`

### ProblÃ¨me: Timeout frÃ©quents
**Solution:** Augmenter timeout (45s), vÃ©rifier connexion internet

## ğŸ“‹ ConformitÃ© et Ã‰thique

**LÃ©galitÃ© du web scraping au Canada:**
- âœ… Scraping de donnÃ©es publiques gÃ©nÃ©ralement lÃ©gal
- âœ… Respect des conditions d'utilisation
- âœ… Rate limiting pour ne pas surcharger serveurs
- âœ… Pas d'authentification non autorisÃ©e
- âœ… Usage commercial interne (analyse de marchÃ©)

**Bonnes pratiques:**
- Respecter robots.txt si prÃ©sent
- Identifier le bot (User-Agent descriptif)
- Limiter frÃ©quence requÃªtes (2-3 sec)
- Scraper pendant heures ouverture

## ğŸ“ Support

**Documentation:** `../PLAN-ANALYSE-PRIX-COMPETITION.md`
**Guide Utilisateur:** `../GUIDE-UTILISATION-SCRAPER.md` (Ã  crÃ©er)
**Logs:** `data/logs/`

## ğŸ“„ License

MIT License - Usage interne Dissan
