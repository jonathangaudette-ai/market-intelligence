# ğŸ§ª ScÃ©nario de Test - RAG Reranking

Guide complet pour valider l'implÃ©mentation du reranking dans le systÃ¨me RAG.

---

## ğŸ“‹ PrÃ©-requis

- âœ… Branche `feature/rag-reranking` dÃ©ployÃ©e
- âœ… Variable `NEXT_PUBLIC_ENABLE_RERANKING=true` dans `.env.local`
- âœ… Au moins 5 documents uploadÃ©s dans la Knowledge Base
- âœ… AccÃ¨s Ã  l'interface Intelligence/Chat

---

## ğŸ”§ Test 1 : Validation Infrastructure (5 min)

### Objectif
VÃ©rifier que l'API Pinecone Inference fonctionne correctement.

### Commande
```bash
npx tsx scripts/test-pinecone-rerank.ts
```

### RÃ©sultat Attendu
```
âœ… SUCCESS - API Inference works!
Model: bge-reranker-v2-m3
Rerank Units: 1

Top 3 Results:
1. [Score: 0.9994]
   Text: "Paris is the capital and most populous city of France."

2. [Score: 0.3941]
   Text: "The Eiffel Tower is a famous landmark in Paris."

3. [Score: 0.1348]
   Text: "Lyon is the third-largest city in France."
```

### âœ… CritÃ¨res de SuccÃ¨s
- [x] Aucune erreur retournÃ©e
- [x] Score du top rÃ©sultat > 0.9
- [x] Rerank Units = 1
- [x] Latence < 2 secondes

---

## ğŸ“Š Test 2 : A/B Test AutomatisÃ© (10 min)

### Objectif
Comparer les rÃ©sultats avec et sans reranking sur vos vraies donnÃ©es.

### Commande
```bash
npx tsx scripts/test-ab-reranking.ts
```

### Ce que le script fait
1. ExÃ©cute 5 requÃªtes de test sur vos documents SANIDÃ‰PÃ”T
2. Compare les rÃ©sultats SANS reranking vs AVEC reranking
3. Mesure la latence et les scores
4. Affiche une analyse comparative

### RÃ©sultat Attendu

Pour chaque requÃªte, vous verrez :

```
ğŸ“Š Query 1/5: "Qui est le fondateur de SANIDÃ‰PÃ”T ?"
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ”µ SANS Reranking (Semantic Search):
  1. [Score: 0.7542] Document-A-propos.pdf
     "SANIDÃ‰PÃ”T a Ã©tÃ© fondÃ© par Jean Dupont en 1985..."
  2. [Score: 0.7201] Historique-entreprise.pdf
  3. [Score: 0.6985] Equipe-direction.pdf
  â±ï¸  Latency: 245ms

ğŸŸ¢ AVEC Reranking (2-Stage Retrieval):
  1. [Score: 0.9876] Document-A-propos.pdf
     "SANIDÃ‰PÃ”T a Ã©tÃ© fondÃ© par Jean Dupont en 1985..."
  2. [Score: 0.8543] Historique-entreprise.pdf
  3. [Score: 0.7821] Equipe-direction.pdf
  â±ï¸  Latency: 312ms (+67ms)

ğŸ“ˆ Analyse:
  - Top result identique: âœ… Oui
  - Score top rÃ©sultat: 0.7542 â†’ 0.9876 (+30.9% improvement)
  - Impact latence: +67ms (+27.3%)
```

### âœ… CritÃ¨res de SuccÃ¨s
- [x] Scores reranked sont **supÃ©rieurs** aux scores semantic (gÃ©nÃ©ralement +20-50%)
- [x] Latence augmente de **50-150ms** (acceptable)
- [x] Top 3 rÃ©sultats sont **plus pertinents** Ã  la requÃªte
- [x] Aucune erreur durant le test

### ğŸ”´ Indicateurs de ProblÃ¨me
- âŒ Scores reranked **infÃ©rieurs** aux scores semantic
- âŒ Latence > 500ms
- âŒ Erreur "Reranking failed, falling back to semantic search"

---

## ğŸ–¥ï¸ Test 3 : Test Manuel Interface Utilisateur (15 min)

### Objectif
Valider que le reranking amÃ©liore la qualitÃ© des rÃ©ponses dans l'interface Intelligence/Chat.

### Ã‰tape par Ã‰tape

#### 3.1 PrÃ©paration (2 min)

1. **Ouvrir l'application** : http://localhost:3010 (ou votre URL de prod)
2. **Se connecter** avec votre compte
3. **Naviguer** vers `Intelligence` â†’ `Chat`
4. **VÃ©rifier** que vous avez au moins 5 documents dans Knowledge Base

#### 3.2 Test SANS Reranking (5 min)

1. **DÃ©sactiver le reranking** :
   ```bash
   # Dans .env.local, changer :
   NEXT_PUBLIC_ENABLE_RERANKING=false
   ```

2. **RedÃ©marrer le serveur** :
   ```bash
   npm run dev
   ```

3. **Poser 3 questions spÃ©cifiques** dans le chat :

   **Question 1** : "Qui a fondÃ© l'entreprise ?"
   - ğŸ“ Noter le **top 3 des sources** affichÃ©es en bas
   - ğŸ“ Noter la **qualitÃ© de la rÃ©ponse** (1-5 Ã©toiles)
   - ğŸ“ Capturer une **capture d'Ã©cran** (optionnel)

   **Question 2** : "Quels sont les services offerts ?"
   - ğŸ“ Noter le **top 3 des sources**
   - ğŸ“ Noter la **qualitÃ© de la rÃ©ponse**

   **Question 3** : "Quelle est l'histoire de l'entreprise ?"
   - ğŸ“ Noter le **top 3 des sources**
   - ğŸ“ Noter la **qualitÃ© de la rÃ©ponse**

#### 3.3 Test AVEC Reranking (5 min)

1. **Activer le reranking** :
   ```bash
   # Dans .env.local, changer :
   NEXT_PUBLIC_ENABLE_RERANKING=true
   ```

2. **RedÃ©marrer le serveur** :
   ```bash
   npm run dev
   ```

3. **Poser les MÃŠMES 3 questions** :
   - ğŸ“ Noter les **nouvelles sources** (ordre peut changer)
   - ğŸ“ Noter la **nouvelle qualitÃ©** de rÃ©ponse
   - ğŸ“ Comparer avec les notes prÃ©cÃ©dentes

#### 3.4 Comparaison et Analyse (3 min)

Remplir le tableau :

| Question | Sources SANS Reranking | Sources AVEC Reranking | QualitÃ© SANS | QualitÃ© AVEC | AmÃ©lioration ? |
|----------|------------------------|------------------------|--------------|--------------|----------------|
| Fondateur | Doc1, Doc2, Doc3 | Doc1, Doc2, Doc3 | 3/5 | 4/5 | âœ… Oui |
| Services | Doc4, Doc5, Doc6 | Doc5, Doc4, Doc7 | 2/5 | 4/5 | âœ… Oui |
| Histoire | Doc8, Doc9, Doc1 | Doc1, Doc8, Doc9 | 3/5 | 5/5 | âœ… Oui |

### âœ… CritÃ¨res de SuccÃ¨s

**Objectif : Au moins 2/3 questions montrent une amÃ©lioration**

- [x] QualitÃ© des rÃ©ponses **augmente** (mÃªme lÃ©gÃ¨rement)
- [x] Sources affichÃ©es sont **plus pertinentes** Ã  la question
- [x] RÃ©ponse **plus prÃ©cise** (contient exactement l'info demandÃ©e)
- [x] Pas de dÃ©gradation visible de performance (< 1 seconde de latence)

### ğŸ”´ Indicateurs de ProblÃ¨me

- âŒ QualitÃ© **diminue** pour 2+ questions
- âŒ Sources **moins pertinentes** qu'avant
- âŒ Latence > 2 secondes
- âŒ Erreurs dans la console (ouvrir DevTools F12)

---

## ğŸ” Test 4 : VÃ©rification Logs & MÃ©triques (5 min)

### Objectif
VÃ©rifier que les mÃ©triques de reranking sont correctement loggÃ©es.

### Commande

1. **Ouvrir la console serveur** (terminal oÃ¹ tourne `npm run dev`)
2. **Poser une question** dans le chat Intelligence
3. **Chercher les logs** du type :

```
[RAG] Rerank metrics: {
  query: 'Qui est le fondateur de SANIDÃ‰PÃ”T ?',
  candidatesCount: 20,
  finalCount: 5,
  latencyMs: 87,
  rerankUnits: 1,
  model: 'bge-reranker-v2-m3'
}
```

### âœ… CritÃ¨res de SuccÃ¨s

- [x] Log `[RAG] Rerank metrics` apparaÃ®t aprÃ¨s chaque requÃªte
- [x] `candidatesCount` = 20 (4x multiplier)
- [x] `finalCount` = 5 (topK)
- [x] `latencyMs` entre 50-200ms
- [x] `rerankUnits` = 1
- [x] `model` = 'bge-reranker-v2-m3'

### ğŸ”´ Indicateurs de ProblÃ¨me

- âŒ Aucun log `[RAG] Rerank metrics` (reranking ne fonctionne pas)
- âŒ Log `[RAG] Reranking failed, falling back to semantic search` (erreur API)
- âŒ `latencyMs` > 500ms (problÃ¨me performance)

---

## ğŸ“ˆ Test 5 : Monitoring CoÃ»ts (Optionnel, 5 min)

### Objectif
VÃ©rifier que les coÃ»ts Pinecone sont dans les limites attendues.

### Ã‰tapes

1. **Se connecter** Ã  [Pinecone Console](https://app.pinecone.io/)
2. **Naviguer** vers votre index `market-intelligence-prod`
3. **Aller dans** Usage / Metrics
4. **VÃ©rifier** le nombre de "Inference Units" consommÃ©s

### Calcul Attendu

```
Queries par jour : 100
CoÃ»t par query : 1 rerank unit Ã— $0.002
CoÃ»t journalier : 100 Ã— $0.002 = $0.20/jour
CoÃ»t mensuel : $0.20 Ã— 30 = $6/mois
```

### âœ… CritÃ¨res de SuccÃ¨s

- [x] Consommation **alignÃ©e** avec le nombre de requÃªtes
- [x] Pas de consommation anormale (ex: 1000 units en 1h)
- [x] CoÃ»t mensuel projetÃ© < $10

---

## âœ… Checklist Finale - Validation ComplÃ¨te

Cochez tous les items avant de merger en production :

### Infrastructure
- [ ] âœ… Test Pinecone Inference API rÃ©ussi
- [ ] âœ… Build Next.js passe sans erreur
- [ ] âœ… Aucune erreur TypeScript

### FonctionnalitÃ©
- [ ] âœ… A/B test montre amÃ©lioration des scores (+20-50%)
- [ ] âœ… Test manuel : 2/3 questions ont une meilleure qualitÃ©
- [ ] âœ… Logs de mÃ©triques apparaissent correctement
- [ ] âœ… Latence acceptable (< 500ms P95)

### Production Ready
- [ ] âœ… Feature flag fonctionne (on/off testÃ©)
- [ ] âœ… Fallback gracieux testÃ© (dÃ©sactiver Pinecone API temporairement)
- [ ] âœ… Monitoring coÃ»ts configurÃ© (Pinecone Console)
- [ ] âœ… Documentation mise Ã  jour

### Rollback Plan
- [ ] âœ… ProcÃ©dure rollback testÃ©e (`NEXT_PUBLIC_ENABLE_RERANKING=false`)
- [ ] âœ… Branche `main` stable identifiÃ©e pour revenir en arriÃ¨re

---

## ğŸš€ DÃ©ploiement en Production

Une fois tous les tests validÃ©s :

```bash
# 1. Merger la branche
git checkout main
git merge feature/rag-reranking

# 2. DÃ©ployer sur Vercel
vercel --prod

# 3. Ajouter la variable d'environnement sur Vercel
# Dashboard Vercel â†’ Settings â†’ Environment Variables
# NEXT_PUBLIC_ENABLE_RERANKING = true

# 4. RedÃ©ployer
vercel --prod
```

### Monitoring Post-DÃ©ploiement (48h)

- **Jour 1** : VÃ©rifier logs, pas d'erreurs
- **Jour 2** : VÃ©rifier coÃ»ts Pinecone, feedback utilisateurs
- **Semaine 1** : Analyser mÃ©triques de qualitÃ© (si disponibles)

---

## ğŸ†˜ Troubleshooting

### ProblÃ¨me : "Reranking failed, falling back to semantic search"

**Cause possible** : API Pinecone Inference non disponible ou API key invalide

**Solution** :
1. VÃ©rifier `PINECONE_API_KEY` dans `.env.local`
2. Tester avec `npx tsx scripts/test-pinecone-rerank.ts`
3. Contacter support Pinecone si nÃ©cessaire

---

### ProblÃ¨me : Latence > 1 seconde

**Cause possible** : Trop de candidats fetchÃ©s ou problÃ¨me rÃ©seau

**Solution** :
1. RÃ©duire `RERANK_MULTIPLIER` de 4 Ã  2 dans `engine.ts`
2. VÃ©rifier la connexion Pinecone (rÃ©gion, network latency)

---

### ProblÃ¨me : Scores reranked plus bas que semantic

**Cause possible** : ModÃ¨le de reranking non adaptÃ© au contenu

**Solution** :
1. Tester avec un autre modÃ¨le : `pinecone-rerank-v0` au lieu de `bge-reranker-v2-m3`
2. VÃ©rifier la qualitÃ© des documents (texte bien extrait ?)

---

## ğŸ“ Support

En cas de problÃ¨me :
1. VÃ©rifier les logs serveur et browser console
2. ExÃ©cuter les 3 scripts de test automatiques
3. Documenter le problÃ¨me avec captures d'Ã©cran
4. Rollback si bloquant : `NEXT_PUBLIC_ENABLE_RERANKING=false`

---

**Bon testing ! ğŸš€**
