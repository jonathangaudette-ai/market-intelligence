# Market Intelligence RAG Application

Complete RAG (Retrieval-Augmented Generation) application for competitive intelligence with FastAPI backend and Next.js frontend.

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- Docker & Docker Compose
- API Keys: Anthropic (Claude), OpenAI, Pinecone

### 1-Command Startup (Docker)

```bash
# Clone and navigate to project
cd market-intelligence

# Create backend .env
cp backend/.env.example backend/.env
# Edit backend/.env with your API keys

# Start everything
docker-compose up
```

Access:
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      NEXT.JS FRONTEND                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Chat Interfaceâ”‚  â”‚Document Uploadâ”‚  â”‚  RAG UI      â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FASTAPI BACKEND                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  RAG Engine  â”‚  â”‚Doc Processor â”‚  â”‚ MCP Client   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Claude  â”‚       â”‚Pinecone â”‚       â”‚PostgreSQLâ”‚
    â”‚Sonnet4.5â”‚       â”‚ Vectors â”‚       â”‚   DB     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Project Structure

```
market-intelligence/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/               # REST endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py        # Chat API
â”‚   â”‚   â”‚   â””â”€â”€ documents.py   # Document management
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_engine.py         # Core RAG
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding.py          # Embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ document_processor.py # PDF processing
â”‚   â”‚   â”‚   â””â”€â”€ mcp_client.py         # Integrations
â”‚   â”‚   â”œâ”€â”€ models/            # Pydantic models
â”‚   â”‚   â”œâ”€â”€ db/                # Database clients
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”‚   â””â”€â”€ main.py            # FastAPI app
â”‚   â”œâ”€â”€ pyproject.toml         # Poetry dependencies
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ src/                       # Next.js frontend
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ rag/              # RAG components
â”‚   â”‚       â”œâ”€â”€ chat-interface.tsx
â”‚   â”‚       â”œâ”€â”€ message-list.tsx
â”‚   â”‚       â”œâ”€â”€ chat-input.tsx
â”‚   â”‚       â””â”€â”€ document-upload.tsx
â”‚   â””â”€â”€ app/                  # Next.js app router
â”‚
â”œâ”€â”€ docker-compose.yml        # Dev environment
â””â”€â”€ RAG_README.md            # This file
```

## ğŸ¯ Features

### Backend (FastAPI)

- âœ… **RAG Engine**: Claude Sonnet 4.5 + Pinecone vector search
- âœ… **Document Processing**: PDF, TXT, MD, DOCX with smart chunking
- âœ… **Embeddings**: OpenAI text-embedding-3-large (3072d)
- âœ… **Conversation Memory**: PostgreSQL-backed chat history
- âœ… **REST API**: Complete CRUD for chat and documents
- âœ… **MCP Integrations**: Firecrawl & Brave Search foundation

### Frontend (Next.js)

- âœ… **Chat Interface**: Real-time conversation with RAG
- âœ… **Source Citations**: Clickable sources with page numbers
- âœ… **Document Upload**: Drag & drop PDF/text files
- âœ… **Conversation History**: Browse previous chats
- âœ… **Responsive Design**: Works on desktop and mobile

## ğŸ› ï¸ Development Setup

### Backend

```bash
cd backend

# Install dependencies
poetry install

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Start PostgreSQL
docker-compose up postgres -d

# Run backend
poetry run uvicorn app.main:app --reload
```

Backend runs on http://localhost:8000

### Frontend

```bash
# Install dependencies
npm install

# Configure environment
# Add to .env.local:
NEXT_PUBLIC_BACKEND_URL=http://localhost:8000

# Run frontend
npm run dev
```

Frontend runs on http://localhost:3000

## ğŸ”§ Configuration

### Backend Environment (.env)

```env
# Required
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
PINECONE_API_KEY=...
DATABASE_URL=postgresql://...

# Optional
FIRECRAWL_API_KEY=...
BRAVE_API_KEY=...
```

### Frontend Environment (.env.local)

```env
NEXT_PUBLIC_BACKEND_URL=http://localhost:8000
```

## ğŸ“– Usage Guide

### 1. Upload a Document

1. Navigate to the "Documents" tab
2. Select a PDF, TXT, or MD file
3. Give it a title
4. Click "Upload Document"
5. Wait for processing (~5-10 seconds)

### 2. Ask Questions

1. Go to the "Chat" tab
2. Type your question about the uploaded documents
3. Get AI-generated answers with source citations
4. Click sources to see page numbers and snippets

### Example Queries

```
"What are Acme Corp's main product features?"
"Compare their pricing to our pricing"
"Summarize the competitive landscape from the report"
"What are their key differentiators?"
```

## ğŸ§ª Testing

### Backend Tests

```bash
cd backend
poetry run pytest
```

### Integration Test

```bash
# Upload a document
curl -X POST http://localhost:8000/api/documents/upload \
  -F "file=@test.pdf" \
  -F "title=Test Document"

# Ask a question
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What is this document about?"}'
```

## ğŸ“Š RAG Pipeline Explained

### Document Ingestion

```
1. Upload PDF
   â†“
2. Extract text by page
   â†“
3. Chunk text (1000 chars, 200 overlap)
   â†“
4. Generate embeddings (OpenAI)
   â†“
5. Store in Pinecone with metadata
   â†“
6. Save metadata in PostgreSQL
```

### Query Processing

```
1. User asks question
   â†“
2. Embed question (OpenAI)
   â†“
3. Search Pinecone (top-5 similar chunks)
   â†“
4. Build context from chunks
   â†“
5. Send to Claude with context
   â†“
6. Return answer + sources
   â†“
7. Save to conversation history
```

## ğŸš€ Deployment

### Backend Deployment

**Option 1: Railway**
```bash
cd backend
railway up
```

**Option 2: Render**
```bash
# Connect GitHub repo
# Add environment variables
# Deploy from dashboard
```

**Option 3: Fly.io**
```bash
cd backend
fly launch
fly secrets set ANTHROPIC_API_KEY=...
fly deploy
```

### Frontend Deployment

**Vercel (Recommended)**
```bash
vercel deploy
```

Set environment variable:
```
NEXT_PUBLIC_BACKEND_URL=https://your-backend.railway.app
```

### Database

- **Supabase**: Free PostgreSQL tier
- **Railway**: PostgreSQL plugin
- **Neon**: Serverless PostgreSQL

### Vector Database

- **Pinecone**: Serverless tier (free to start)

## ğŸ’° Cost Breakdown

For 100 documents, 1000 queries/month:

| Service | Cost/Month |
|---------|-----------|
| Claude API | $50-150 |
| OpenAI Embeddings | $10-30 |
| Pinecone Serverless | $0-20 |
| PostgreSQL (Supabase) | $0 (free tier) |
| Backend Hosting (Railway) | $0-5 (free tier) |
| Frontend Hosting (Vercel) | $0 (free tier) |
| **Total** | **$60-205** |

## ğŸ” API Examples

### Upload Document

```bash
curl -X POST http://localhost:8000/api/documents/upload \
  -F "file=@competitor-report.pdf" \
  -F "title=Acme Corp Q4 Report"
```

### Chat Query

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What are the key features?",
    "top_k": 5
  }'
```

### List Documents

```bash
curl http://localhost:8000/api/documents/
```

### Get Conversation History

```bash
curl http://localhost:8000/api/chat/history/{conversation_id}
```

## ğŸ› Troubleshooting

### Backend won't start

```bash
# Check PostgreSQL is running
docker-compose ps postgres

# Check environment variables
cat backend/.env

# View logs
docker-compose logs backend
```

### Frontend can't connect to backend

```bash
# Verify backend is running
curl http://localhost:8000/health

# Check NEXT_PUBLIC_BACKEND_URL
echo $NEXT_PUBLIC_BACKEND_URL
```

### Pinecone errors

```bash
# Verify API key
# Check index name matches config
# Pinecone index is auto-created on first run
```

### Out of memory

```bash
# Increase chunk size
echo "CHUNK_SIZE=2000" >> backend/.env

# Or reduce batch size in embedding service
```

## ğŸ“š Documentation

- [Backend README](backend/README.md) - Complete backend documentation
- [API Docs](http://localhost:8000/docs) - Interactive API documentation
- [Plan Implementation](plan-implementation-app-rag.md) - Original planning document

## ğŸ“ Learning Resources

- [Claude API Docs](https://docs.anthropic.com/)
- [Pinecone Docs](https://docs.pinecone.io/)
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [Next.js Docs](https://nextjs.org/docs)

## ğŸ¤ Contributing

1. Create feature branch
2. Make changes
3. Run tests
4. Submit pull request

## ğŸ“ License

Proprietary - Market Intelligence Platform

## ğŸ†˜ Support

For questions or issues:
- Check backend logs: `docker-compose logs backend`
- Check frontend logs: Browser console
- Review API docs: http://localhost:8000/docs

---

**Built with**: FastAPI + Next.js + Claude Sonnet 4.5 + Pinecone + PostgreSQL
